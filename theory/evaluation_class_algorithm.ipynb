{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cassification Algorithm Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "\n",
    "<img src=\"confusion_matrix.png\"  style=\"width: 500px;\"/>\n",
    "\n",
    "Correct values = 85\n",
    "\n",
    "Error = 31\n",
    "\n",
    "% correct (accuracy score) = 73.27%\n",
    "\n",
    "% error = 26.72%\n",
    "\n",
    "<img src=\"confusion_matrix2.png\"  style=\"width: 300px;\"/>\n",
    "\n",
    "Lower left error = **Type 1 error** (false positive) - when the predictive value is positive but the correct class is negative\n",
    "\n",
    "Upper right error =  **Type 2 error** (false negative) - when the predictive value is negative but the correct class is positive\n",
    "\n",
    "### Result Evaluation\n",
    "\n",
    "- The **context** of the % of correctness/error is important to evaluate how good/bad is the result. Also, the % of each type of error is important to consider. For example: type 2 error can be more costly than type 1 and it's possible to decrease the type 2 error with an increase of type 1 and a decrease of accuracy but at the end this result will be more profitable than the one with simply higher accuracy.\n",
    "\n",
    "- **Number of classes**. For ex. high, moderate and low are 3 classes and the chance to randomly get correct is 33.33%. So the % of correctness have to be higher than 33.33%\n",
    "\n",
    "- **Zero rules**: the class with the higher number is choosen. Rule used to compare with the algorithm result. For example: Moderate has the higher number (40 and 34.48%) and with it the higher chances for the new person to be moderate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall\n",
    "\n",
    "| Fraud |  Predict: True | Predict: False |\n",
    "|-------|:------|------:|\n",
    "| True  |  200  |  50   |\n",
    "| False |  50   |  700  |\n",
    "\n",
    "<br>\n",
    "\n",
    "| Sick  |  Predict: True | Predict: False |\n",
    "|-------|:------|------:|\n",
    "| True  |  1  |  8   |\n",
    "| False |  1  |  90  |\n",
    "\n",
    "**Precision** - when predicted TRUE and was correct\n",
    "\n",
    "Precision Fraud: 200/(200+50) = 0.8\n",
    "\n",
    "Precision Sick: 1/(1+1): 0.5\n",
    "\n",
    "**Recall** - when the class is TRUE and the model predicted correct\n",
    "\n",
    "Recall Fraud: 200/(200+50) = 0.8\n",
    "\n",
    "Recall Sick: 1/(1+8) = 0.11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold Cross Validation\n",
    "\n",
    "K: number to divide the dataset in K sets\n",
    "\n",
    "<img src=\"cross_validation.png\"  style=\"width: 500px;\"/>\n",
    "\n",
    "All data are used, so there is no separation of trainning and testin data.\n",
    "\n",
    "Usually K=10 is used and it is not recommended high values of K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underfitting and Overfitting\n",
    "\n",
    "**Underfitting**: when the problem is complex but the model used is too simple\n",
    "\n",
    "- Bad results on training data.\n",
    "\n",
    "**Overfitting**: when data adapts too much to training data, or, model is addicted to training data\n",
    "\n",
    "- *Good* results on training data but *bad* on test data\n",
    "\n",
    "- Very specific\n",
    "\n",
    "- Algorithm memorized data\n",
    "\n",
    "- Mistakes on new different data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

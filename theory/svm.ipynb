{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines - SVM\n",
    "\n",
    "In general, SVM results are better than other ml methods.\n",
    "\n",
    "- Used in complex problems: voice, images and caracters recognition\n",
    "- In the past was the most efficient method. Now it loses to neural networks\n",
    "\n",
    "The method learns separation hyperplans with **maximum margin** of distance (biggest distance).\n",
    "\n",
    "- The biggest the distance the better is the classification.\n",
    "\n",
    "The points close to the line or hyperplan are the support vectors.\n",
    "\n",
    "<img src=\"svm.png\"  style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vectors\n",
    "\n",
    "The method works to find the support vectors, as with them it is possible to construct the hyperplan.\n",
    "\n",
    "- Support vectors are data (points of data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convex hulls\n",
    "\n",
    "It's a techinic to find a way to draw the hyperplan.\n",
    "\n",
    "Distance between the convex hulls.\n",
    "\n",
    "<img src=\"convex_hull.png\"  style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math approach\n",
    "\n",
    "Dot product: function of the product of data dots: $\\vec{w}*\\vec{y} + b = 0$\n",
    "\n",
    "Where $w$ is the normal vector (but not necessarily normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost and Errors\n",
    "\n",
    "Errors of classification is possible but the algorithm tries to minimize it. \n",
    "\n",
    "Formula: $\\frac{1}{2}|2|^2 + c\\sum_{i}a_i$\n",
    "\n",
    "$c$ is the punishment for wrong classification. This paramter is choosen previously\n",
    "\n",
    "High $c$: tries 100% of separation\n",
    "\n",
    "Low $c$: allows more errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear VS non linear SVM \n",
    "\n",
    "Linear: '**and'** logic operator works for separation.\n",
    "\n",
    "Non-linear: '**xor**' logic operator works for separation. ('xor' is 'exclusive or')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non linear SVM - Kernel Trick\n",
    "\n",
    "Kernel trick: It change vectors to be able to work with linear hyperplan. \n",
    "\n",
    "- Linear Kernel: It does it by using one more dimention information/visualization. $K(x,y) = (x*y)$\n",
    "\n",
    "- Gaussian: $K(x,y) = \\exp(\\frac{||x-x_i||^2}{2\\sigma^2})$\n",
    "\n",
    "- Polynomial: $K(x,y) =(x*y)^p$\n",
    "\n",
    "- Tangent Hyperbolic (Sigmoid function): $K(x,y) =\\tanh(x*y-\\Theta)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slack Variable\n",
    "\n",
    "SVM algorithm learns with the given atributes and creates new atributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros VS Cons\n",
    "\n",
    "Pros:\n",
    "- Noise/outliers doesn't disturb much the result\n",
    "- Used for both classification and regression\n",
    "- Learns concepts/atributes not given\n",
    "- Easier than neural network\n",
    "\n",
    "Cons:\n",
    "- Necessary to try several combination of parameters\n",
    "- Slow, so it doesn't works well with big datasets\n",
    "- Black box"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
